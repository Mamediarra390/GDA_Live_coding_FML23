{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mamediarra390/GDA_Live_coding_FML23/blob/main/Mame_Diarra_Diop_Live_coding_GDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GDA Implementation.\n",
        "\n",
        "Implement the Gaussian Discriminant Analysis (GDA) learning algorithm following the steps as discussed in class.\n",
        "\n",
        "INSTRUCTION: Rename your notebook as: <br>\n",
        "`firstName_LastName_Live_coding_GDA.ipynb`.\n",
        "\n",
        "Notes: \n",
        "* Do not use any built-in functions to complete a task;\n",
        "* Do not import additional libraries."
      ],
      "metadata": {
        "id": "g17Z46tmw2oZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aT5nlL-QTKwv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data\n",
        "def generate_data():\n",
        "  x, y = make_classification(n_samples= 1000, n_features=3, n_redundant=0, \n",
        "                           n_informative=3, random_state=1, \n",
        "                           n_clusters_per_class=1)\n",
        "  \n",
        "  return x,y\n",
        "\n",
        "x,y= generate_data()\n",
        "print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-lL4Yq9Tbzn",
        "outputId": "379c346a-96a0-4720-ef06-a031de689041"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 3) (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(x,y, train_size= 0.8):\n",
        "    # shuffle the data to randomize the train/test split\n",
        "    indice = np.arange(x.shape[0])\n",
        "    np.random.permutation(indice)\n",
        "    x= x[indice]\n",
        "    y = y[indice]\n",
        "    num = int(train_size * x.shape[0])\n",
        "    x_train = x[:num]\n",
        "    y_train = y[:num]\n",
        "    x_test = x[num:]\n",
        "    y_test = y[num:]\n",
        "    return x_train, x_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "EUgiWLDhUAAK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test= split_data(x,y, train_size= 0.8) # split your data into x_train, x_test, y_train, y_test\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr2Akm_A_FcJ",
        "outputId": "efa351a0-7422-4100-f170-e76017064fce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 3) (800,) (200, 3) (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def covariance(x, mu):\n",
        "\n",
        "  # Easy way: cov= np.cov(x, rowvar=0) but do not use it. One can use it to assess his/her result.\n",
        "  N,d = x.shape\n",
        "  sigma = np.zeros((d,d))\n",
        "  K=mu.shape[0]\n",
        "  for k in range(K):\n",
        "    for i in range(d):\n",
        "      for j in range(d):\n",
        "        sigma[i,j] = 1/(N-1)*np.sum((x[:,i] - mu[i]) * (x[:,j] - mu[j])) \n",
        "  return sigma"
      ],
      "metadata": {
        "id": "FrJ7GfXBHNxD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "covariance(x, x.mean(axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT3LmUrFb0ge",
        "outputId": "a2795b7e-b52e-48ec-9c96-bec09a043d47"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.84495325, 0.02790646, 1.00137533],\n",
              "       [0.02790646, 1.00170721, 0.05539176],\n",
              "       [1.00137533, 0.05539176, 1.74832   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toy_x = np.random.randn(10,3)\n",
        "toy_mu = np.mean(toy_x, 0)\n",
        "print(toy_x.shape, toy_mu.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AiKjzObGxiE",
        "outputId": "13798268-3b75-4896-cc99-91b4200abfa5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 3) (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.cov(toy_x, rowvar=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzsPlAYqHbHo",
        "outputId": "3bff7d62-aac6-4a5e-d61c-a40bb8659bca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.82739692, -0.04873264,  0.09037384],\n",
              "       [-0.04873264,  0.41972606,  0.06164041],\n",
              "       [ 0.09037384,  0.06164041,  1.76451134]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import argmax\n",
        "from math import pi\n",
        "from numpy.random import Philox\n",
        "class GDA:\n",
        "  def __init__(self):\n",
        "    ## set mu, phi and sigma to None\n",
        "    self.mu = None\n",
        "    self.phi =None\n",
        "    self.sigma = None\n",
        "\n",
        "  def fit(self,x,y):\n",
        "    k=np.unique(y).shape[0] # Number of class.\n",
        "    d=x.shape[1]  # input dim\n",
        "    m=x.shape[0]  # Number of examples.\n",
        "    \n",
        "    ## Initialize mu, phi and sigma\n",
        "    self.mu= np.zeros((k,d))#: kxd, i.e., each row contains an individual class mu.\n",
        "    self.sigma= np.zeros((k,d,d))#: kxdxd, i.e., each row contains an individual class sigma.\n",
        "    self.phi= np.zeros(k)# d-dimension\n",
        "    for label in range(k):\n",
        "      self.phi[label] = np.sum(label == y)/x.shape[0]\n",
        "      #idx=np.where(y==label)\n",
        "      self.mu[label] = np.mean(x[label == y], axis=0)\n",
        "      self.sigma[label] = covariance(x[label == y], self.mu[label])\n",
        "\n",
        "    ## START THE LEARNING: estimate mu, phi and sigma.\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def predict_proba(self,x):\n",
        "    # reshape or flatt x.\n",
        "    #x= x.reshape[0]\n",
        "    d=x.shape[1]\n",
        "    k_class= self.mu.shape[0]# Number of classes we have in our case it's k = 2\n",
        "    print(x.shape[0])\n",
        "    ## START THE LEARNING: estimate mu, phi and sigma.\n",
        "    #mu = self.mu\n",
        "    #phi =self.phi\n",
        "    #sigma = self.sigma\n",
        "    pro = np.zeros((x.shape[0], k_class))\n",
        "    \n",
        "    for lab in range(k_class):\n",
        "      for i in range(x.shape[0]):\n",
        "        coeff = 1/((2*pi)**(d/2)) *(np.linalg.det(self.sigma[lab])**(1/2))\n",
        "        pro[i,lab] = coeff * np.exp(-(1/2)*(x[i] - self.mu[lab]).T@np.linalg.inv(self.sigma[lab])@(x[i] - self.mu[lab]))\n",
        "    return pro\n",
        "\n",
        "\n",
        "\n",
        "  def predict(self,x):\n",
        "    predict_proba = self.predict_proba(x)*self.phi\n",
        "    y_pred = np.argmax(predict_proba, axis = 1)\n",
        "    return y_pred\n",
        "  \n",
        "  def accuracy(self, y, ypreds):\n",
        "    accu = np.mean(y==ypreds)\n",
        "    return accu"
      ],
      "metadata": {
        "id": "1ocKLDAfceF0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gTO_Ve4S4nlf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= GDA()\n",
        "model.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "l_qO0Yp1c3Is"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.mu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tGE2OlU53N4",
        "outputId": "93fbac4a-d517-49a2-8de4-034119e47002"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.00201779,  1.00494482,  0.99548846],\n",
              "       [-1.01641736,  0.96824826, -0.90433708]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.phi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4iDWxKC55si",
        "outputId": "b23db188-9b81-4c51-cfda-f08efe44a225"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.495, 0.505])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.sigma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEZ0bORA58JW",
        "outputId": "df321f94-17a3-4b3f-9665-04d144bed923"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.90164773, -0.43335029, -0.06500866],\n",
              "        [-0.43335029,  1.68747351,  0.10027055],\n",
              "        [-0.06500866,  0.10027055,  0.0384381 ]],\n",
              "\n",
              "       [[ 0.7647548 ,  0.35278165,  0.0911074 ],\n",
              "        [ 0.35278165,  0.34171233, -0.08598807],\n",
              "        [ 0.0911074 , -0.08598807,  1.62087217]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yproba = model.predict_proba(x_test)\n",
        "yproba.shape"
      ],
      "metadata": {
        "id": "NKY1eojY1l4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a05d4142-4b6f-4132-86d4-ba515c8dab7c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypreds= model.predict(x_test)\n",
        "ypreds\n"
      ],
      "metadata": {
        "id": "D4clV6PK1UJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac3705c-412a-4415-de01-9b282219ad6b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
              "       1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.accuracy(y_test, ypreds)"
      ],
      "metadata": {
        "id": "QgG1xPUg1ULw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af3d21d-575c-4ca3-adce-33f056967cab"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.965"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OpXYY-yj1UOj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.validation import check_X_y\n",
        "class LogisticRegression:           \n",
        "  '''\n",
        "  The goal of this class is to create a LogisticRegression class, \n",
        "  that we will use as our model to classify data point into a corresponding class\n",
        "  '''\n",
        "  def __init__(self,lr,n_epochs):\n",
        "    self.lr = lr\n",
        "    self.n_epochs = n_epochs\n",
        "    self.train_losses = []\n",
        "    self.w = None\n",
        "    self.weight = []\n",
        "\n",
        "  def add_ones(self, x):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    N = np.ones((x.shape[0],1))\n",
        "    return np.hstack((N,x))\n",
        "  \n",
        "    #### END CODE ####\n",
        "\n",
        "  def sigmoid(self, x):\n",
        "    ##### WRITE YOUR CODE HERE ####\n",
        "    sig = 1/(1 + np.exp(-x@self.w))\n",
        "    return sig\n",
        "    #### END CODE ####\n",
        "    \n",
        "\n",
        "  def cross_entropy(self, x, y_true):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    y_pred = self.sigmoid(x)\n",
        "    N,D = x.shape\n",
        "    loss = (-1/N)* np.sum(y_true * np.log(y_pred) + (1- y_true) * np.log(1 - y_pred))\n",
        "    return loss\n",
        "    #### END CODE ####\n",
        "  \n",
        "  def predict_proba(self,x):  #This function will use the sigmoid function to compute the probalities\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    x= self.add_ones(x)\n",
        "    proba = self.sigmoid(x)\n",
        "    return proba\n",
        "    #### END CODE ####\n",
        "\n",
        "  def predict(self,x):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    probas = self.predict_proba(x)\n",
        "    output = [0 if p<0.5 else 1 for p in probas]#np.where(probas > 0.5, 1, 0)      #convert the probalities into 0 and 1 by using a treshold=0.5\n",
        "    return output\n",
        "    #### END CODE ####\n",
        "\n",
        "  def fit(self,x,y):\n",
        "    # Add ones to x\n",
        "    x = self.add_ones(x)\n",
        "\n",
        "    # reshape y if needed\n",
        "    y = y.reshape(-1,1)\n",
        "\n",
        "    # Initialize w to zeros vector >>> (x.shape[1])\n",
        "    self.w = np.zeros((x.shape[1],1))\n",
        "\n",
        "    for epoch in range(self.n_epochs):\n",
        "      # make predictions\n",
        "      ypred = self.sigmoid(x)\n",
        "\n",
        "      #compute the gradient\n",
        "\n",
        "      dl = (-1/x.shape[0])*x.T@(y- ypred)\n",
        "\n",
        "      #update rule\n",
        "      self.w = self.w - self.lr * dl\n",
        "\n",
        "      #Compute and append the training loss in a list\n",
        "      loss = self.cross_entropy(x, y)\n",
        "\n",
        "      if epoch%100 == 0:\n",
        "        print(f'loss for epoch {epoch}  : {loss}')\n",
        "\n",
        "  def accuracy(self,y_true, y_pred):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    acc = np.mean(y_true==y_pred)*100\n",
        "    return acc\n",
        "    #### END CODE ####"
      ],
      "metadata": {
        "id": "8cvRcUO2rtKo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= LogisticRegression(lr=0.01,n_epochs=10000)\n",
        "model.fit(x_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiK9SylomiEL",
        "outputId": "b2bf73d2-d521-4797-eb56-033f69631bd7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 0  : 0.688363021140951\n",
            "loss for epoch 100  : 0.422640627331724\n",
            "loss for epoch 200  : 0.32872318242874854\n",
            "loss for epoch 300  : 0.2821421669089025\n",
            "loss for epoch 400  : 0.2542740474046796\n",
            "loss for epoch 500  : 0.23564711029252902\n",
            "loss for epoch 600  : 0.22226529615438467\n",
            "loss for epoch 700  : 0.21215414670829633\n",
            "loss for epoch 800  : 0.20422490633561083\n",
            "loss for epoch 900  : 0.1978269301185786\n",
            "loss for epoch 1000  : 0.1925467797763679\n",
            "loss for epoch 1100  : 0.1881087412082297\n",
            "loss for epoch 1200  : 0.1843216354180446\n",
            "loss for epoch 1300  : 0.18104857389456974\n",
            "loss for epoch 1400  : 0.17818886930242633\n",
            "loss for epoch 1500  : 0.17566674984854355\n",
            "loss for epoch 1600  : 0.1734240619215231\n",
            "loss for epoch 1700  : 0.17141540446185388\n",
            "loss for epoch 1800  : 0.16960479715861454\n",
            "loss for epoch 1900  : 0.16796334511586686\n",
            "loss for epoch 2000  : 0.1664675679074136\n",
            "loss for epoch 2100  : 0.1650981819047337\n",
            "loss for epoch 2200  : 0.16383919824898385\n",
            "loss for epoch 2300  : 0.16267724470593475\n",
            "loss for epoch 2400  : 0.1616010489755026\n",
            "loss for epoch 2500  : 0.1606010402007026\n",
            "loss for epoch 2600  : 0.1596690382039512\n",
            "loss for epoch 2700  : 0.1587980086563895\n",
            "loss for epoch 2800  : 0.15798186837458894\n",
            "loss for epoch 2900  : 0.15721532913487252\n",
            "loss for epoch 3000  : 0.15649377137644796\n",
            "loss for epoch 3100  : 0.1558131413097996\n",
            "loss for epoch 3200  : 0.15516986650912049\n",
            "loss for epoch 3300  : 0.15456078621805436\n",
            "loss for epoch 3400  : 0.1539830934540146\n",
            "loss for epoch 3500  : 0.15343428663940764\n",
            "loss for epoch 3600  : 0.15291212897556064\n",
            "loss for epoch 3700  : 0.15241461414782578\n",
            "loss for epoch 3800  : 0.15193993723752383\n",
            "loss for epoch 3900  : 0.15148646993936335\n",
            "loss for epoch 4000  : 0.15105273935732766\n",
            "loss for epoch 4100  : 0.15063740978926682\n",
            "loss for epoch 4200  : 0.15023926701915818\n",
            "loss for epoch 4300  : 0.1498572047226457\n",
            "loss for epoch 4400  : 0.14949021266091905\n",
            "loss for epoch 4500  : 0.14913736639395866\n",
            "loss for epoch 4600  : 0.14879781828950808\n",
            "loss for epoch 4700  : 0.14847078964103827\n",
            "loss for epoch 4800  : 0.14815556373814867\n",
            "loss for epoch 4900  : 0.14785147975764484\n",
            "loss for epoch 5000  : 0.14755792736398823\n",
            "loss for epoch 5100  : 0.14727434192476044\n",
            "loss for epoch 5200  : 0.14700020026087812\n",
            "loss for epoch 5300  : 0.1467350168630614\n",
            "loss for epoch 5400  : 0.14647834051591585\n",
            "loss for epoch 5500  : 0.14622975127927715\n",
            "loss for epoch 5600  : 0.14598885778345916\n",
            "loss for epoch 5700  : 0.14575529480096205\n",
            "loss for epoch 5800  : 0.14552872106222128\n",
            "loss for epoch 5900  : 0.1453088172872534\n",
            "loss for epoch 6000  : 0.14509528440870623\n",
            "loss for epoch 6100  : 0.14488784196494872\n",
            "loss for epoch 6200  : 0.1446862266445174\n",
            "loss for epoch 6300  : 0.1444901909655499\n",
            "loss for epoch 6400  : 0.1442995020758259\n",
            "loss for epoch 6500  : 0.14411394066076336\n",
            "loss for epoch 6600  : 0.14393329994821058\n",
            "loss for epoch 6700  : 0.14375738480017464\n",
            "loss for epoch 6800  : 0.14358601088275774\n",
            "loss for epoch 6900  : 0.14341900390655993\n",
            "loss for epoch 7000  : 0.14325619893067057\n",
            "loss for epoch 7100  : 0.14309743972412617\n",
            "loss for epoch 7200  : 0.14294257817937744\n",
            "loss for epoch 7300  : 0.14279147377289203\n",
            "loss for epoch 7400  : 0.14264399306853343\n",
            "loss for epoch 7500  : 0.14250000925981224\n",
            "loss for epoch 7600  : 0.14235940174750614\n",
            "loss for epoch 7700  : 0.14222205574950184\n",
            "loss for epoch 7800  : 0.14208786194002765\n",
            "loss for epoch 7900  : 0.14195671611572522\n",
            "loss for epoch 8000  : 0.14182851888625986\n",
            "loss for epoch 8100  : 0.14170317538738955\n",
            "loss for epoch 8200  : 0.14158059501461334\n",
            "loss for epoch 8300  : 0.1414606911756958\n",
            "loss for epoch 8400  : 0.14134338106052355\n",
            "loss for epoch 8500  : 0.14122858542689287\n",
            "loss for epoch 8600  : 0.14111622840095403\n",
            "loss for epoch 8700  : 0.14100623729115366\n",
            "loss for epoch 8800  : 0.14089854241462052\n",
            "loss for epoch 8900  : 0.14079307693503068\n",
            "loss for epoch 9000  : 0.1406897767110752\n",
            "loss for epoch 9100  : 0.1405885801547267\n",
            "loss for epoch 9200  : 0.14048942809857143\n",
            "loss for epoch 9300  : 0.14039226367153432\n",
            "loss for epoch 9400  : 0.14029703218238174\n",
            "loss for epoch 9500  : 0.1402036810104366\n",
            "loss for epoch 9600  : 0.14011215950298817\n",
            "loss for epoch 9700  : 0.14002241887891909\n",
            "loss for epoch 9800  : 0.13993441213811253\n",
            "loss for epoch 9900  : 0.1398480939762353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yproba = model.predict_proba(x_test)\n",
        "yproba.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v1d7baEmqDv",
        "outputId": "4d87209a-c5b6-4838-9ac2-bf39d7e4d7df"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.accuracy(y_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHcOW_uqnRlj",
        "outputId": "a1db239d-b0e4-4cb3-9584-b657a852709a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100.0"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}